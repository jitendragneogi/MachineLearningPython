{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to jitendragneogi@gmail.com and will expire on July 29, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\IBM_AD~1\\AppData\\Local\\Temp\\graphlab_server_1473179883.log.0\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Linear regression:</pre>"
      ],
      "text/plain": [
       "Linear regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 21613</pre>"
      ],
      "text/plain": [
       "Number of examples          : 21613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of features          : 17</pre>"
      ],
      "text/plain": [
       "Number of features          : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 17</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 18</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.000002  | 1.324075     | 6962915.603493     | 426631.749026 |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.000002  | 1.324075     | 6962915.603493     | 426631.749026 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.000002  | 1.487085     | 6843144.200219     | 392488.929838 |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.000002  | 1.487085     | 6843144.200219     | 392488.929838 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.000002  | 1.518086     | 6831900.032123     | 385340.166783 |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.000002  | 1.518086     | 6831900.032123     | 385340.166783 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.000002  | 1.547088     | 6847166.848958     | 384842.383767 |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.000002  | 1.547088     | 6847166.848958     | 384842.383767 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.000002  | 1.579090     | 6869667.895833     | 385998.458623 |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.000002  | 1.579090     | 6869667.895833     | 385998.458623 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.000002  | 1.609092     | 6847177.773672     | 380824.455891 |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.000002  | 1.609092     | 6847177.773672     | 380824.455891 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_coefficients(model):    \n",
    "    # Get the degree of the polynomial\n",
    "    deg = len(model.coefficients['value'])-1\n",
    "\n",
    "    # Get learned parameters as a list\n",
    "    w = list(model.coefficients['value'])\n",
    "\n",
    "    # Numpy has a nifty function to print out polynomials in a pretty way\n",
    "    # (We'll use it, but it needs the parameters in the reverse order)\n",
    "    print 'Learned polynomial for degree ' + str(deg) + ':'\n",
    "    w.reverse()\n",
    "    print numpy.poly1d(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_penalty = 1.000000e+10\n",
      "number of nonzeros = 6\n",
      "Learned polynomial for degree 17:\n",
      "       14         13         5         4        3\n",
      "20.02 x  + 842.1 x  + 350.1 x + 24.42 x + 8469 x + 2.749e+05\n"
     ]
    }
   ],
   "source": [
    "print 'l1_penalty = %e' % 1e10\n",
    "print 'number of nonzeros = %d' % (model_all.coefficients['value']).nnz()\n",
    "print_coefficients(model_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bedrooms', 'bedrooms_square', 'bathrooms', 'sqft_living', 'sqft_living_sqrt', 'sqft_lot', 'sqft_lot_sqrt', 'floors', 'floors_square', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']\n"
     ]
    }
   ],
   "source": [
    "print all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_residual_sum_of_squares(model, data, outcome):\n",
    "    # First get the predictions\n",
    "    predictions = model.predict(data)\n",
    "    # Then compute the residuals/errors\n",
    "    residuals = predictions - outcome\n",
    "    # Then square and add them up\n",
    "    residuals_square = residuals*residuals\n",
    "    RSS = residuals_square.sum()\n",
    "    return(RSS)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error for l1 penalty value 10.000000 is 625766285142459.875000\n",
      "Validation Error for l1 penalty value 31.622777 is 625766285362394.125000\n",
      "Validation Error for l1 penalty value 100.000000 is 625766286057885.000000\n",
      "Validation Error for l1 penalty value 316.227766 is 625766288257224.625000\n",
      "Validation Error for l1 penalty value 1000.000000 is 625766295212186.750000\n",
      "Validation Error for l1 penalty value 3162.277660 is 625766317206080.500000\n",
      "Validation Error for l1 penalty value 10000.000000 is 625766386760658.125000\n",
      "Validation Error for l1 penalty value 31622.776602 is 625766606749278.500000\n",
      "Validation Error for l1 penalty value 100000.000000 is 625767302791634.125000\n",
      "Validation Error for l1 penalty value 316227.766017 is 625769507643886.250000\n",
      "Validation Error for l1 penalty value 1000000.000000 is 625776517727024.000000\n",
      "Validation Error for l1 penalty value 3162277.660168 is 625799062845467.000000\n",
      "Validation Error for l1 penalty value 10000000.000000 is 625883719085425.250000\n",
      "\n",
      "Lowest Validation Error for l1 penalty value 10.000000 is 625766285142459.875000\n"
     ]
    }
   ],
   "source": [
    "lowest_rss = 0.0\n",
    "lowest_l1_penalty = 0.0\n",
    "for l1_penalty in np.logspace(1, 7, num=13):\n",
    "    model1 = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              verbose = False, validation_set = None,\n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty)\n",
    "    rss_validation = get_residual_sum_of_squares(model1, validation, validation['price'])\n",
    "    print \"Validation Error for l1 penalty value %f is %f\"%(l1_penalty, rss_validation)   \n",
    "    \n",
    "    if (lowest_rss == 0.0 or lowest_rss > rss_validation):\n",
    "        lowest_rss = rss_validation\n",
    "        lowest_l1_penalty = l1_penalty\n",
    "        \n",
    "print \"\"\n",
    "print \"Lowest Validation Error for l1 penalty value %f is %f\"%(lowest_l1_penalty, lowest_rss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              verbose = False, validation_set = None,\n",
    "                                              l2_penalty=0., l1_penalty=lowest_l1_penalty)\n",
    "\n",
    "   \n",
    "rss_test = get_residual_sum_of_squares(model2, testing, testing['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on Test data for l1 penalty value 10.000000 is 156983602381664.187500\n"
     ]
    }
   ],
   "source": [
    "print \"RSS on Test data for l1 penalty value %f is %f\"%(lowest_l1_penalty, rss_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_penalty = 1.000000e+01\n",
      "number of nonzeros = 18\n",
      "Learned polynomial for degree 17:\n",
      "       17         16         15         14        13        12\n",
      "56.07 x  + 9.434 x  + 122.4 x  + 43.29 x  + 6207 x  + 6609 x \n",
      "              11             10             9            8         7\n",
      " + 9.331e+04 x  + 6.019e+05 x  + 1.292e+04 x + 2.12e+04 x + 148.3 x\n",
      "             6        5         4             3       2\n",
      " + 0.003484 x + 1125 x + 39.12 x + 2.541e+04 x + 937 x + 7937 x + 1.899e+04\n"
     ]
    }
   ],
   "source": [
    "print 'l1_penalty = %e' %lowest_l1_penalty\n",
    "print 'number of nonzeros = %d' % (model2.coefficients['value']).nnz()\n",
    "print_coefficients(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_penalty = 1.000000e+08\n",
      "number of nonzeros = 18\n",
      "l1_penalty = 1.274275e+08\n",
      "number of nonzeros = 18\n",
      "l1_penalty = 1.623777e+08\n",
      "number of nonzeros = 18\n",
      "l1_penalty = 2.069138e+08\n",
      "number of nonzeros = 18\n",
      "l1_penalty = 2.636651e+08\n",
      "number of nonzeros = 17\n",
      "l1_penalty = 3.359818e+08\n",
      "number of nonzeros = 17\n",
      "l1_penalty = 4.281332e+08\n",
      "number of nonzeros = 17\n",
      "l1_penalty = 5.455595e+08\n",
      "number of nonzeros = 17\n",
      "l1_penalty = 6.951928e+08\n",
      "number of nonzeros = 17\n",
      "l1_penalty = 8.858668e+08\n",
      "number of nonzeros = 16\n",
      "l1_penalty = 1.128838e+09\n",
      "number of nonzeros = 15\n",
      "l1_penalty = 1.438450e+09\n",
      "number of nonzeros = 15\n",
      "l1_penalty = 1.832981e+09\n",
      "number of nonzeros = 13\n",
      "l1_penalty = 2.335721e+09\n",
      "number of nonzeros = 12\n",
      "l1_penalty = 2.976351e+09\n",
      "number of nonzeros = 10\n",
      "l1_penalty = 3.792690e+09\n",
      "number of nonzeros = 6\n",
      "\n",
      "2976351441.63\n",
      "number of nonzeros = 10\n",
      "\n",
      "3792690190.73\n",
      "number of nonzeros = 6\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in l1_penalty_values:\n",
    "    model3 = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              verbose = False, validation_set = None,\n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty)\n",
    "    \n",
    "    print 'l1_penalty = %e' %l1_penalty \n",
    "    print 'number of nonzeros = %d' % (model3.coefficients['value']).nnz() \n",
    "    current_non_zero = (model3.coefficients['value']).nnz() \n",
    "    if current_non_zero > max_nonzeros:\n",
    "            l1_penalty_min = l1_penalty\n",
    "            min_current_non_zero = current_non_zero\n",
    "            \n",
    "    if (current_non_zero < max_nonzeros) is True:\n",
    "        l1_penalty_max = l1_penalty\n",
    "        max_current_non_zero = current_non_zero\n",
    "        break\n",
    "            \n",
    "print \"\" \n",
    "print l1_penalty_min\n",
    "print 'number of nonzeros = %d' % min_current_non_zero\n",
    "\n",
    "print \"\" \n",
    "print l1_penalty_max\n",
    "print 'number of nonzeros = %d' % max_current_non_zero "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = \n",
    "l1_penalty_max = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error for l1 penalty value 2976351441.631313 is 966925692362084.500000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3019316638.952415 is 974019450084556.125000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3062281836.273517 is 981188367942452.750000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3105247033.594619 is 989328342459474.000000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3148212230.915721 is 998783211265891.250000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3191177428.236824 is 1008477167020094.000000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3234142625.557926 is 1018298780553819.750000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3277107822.879028 is 1028247992205977.250000\n",
      "number of nonzeros = 10\n",
      "Validation Error for l1 penalty value 3320073020.200130 is 1034616909232828.125000\n",
      "number of nonzeros = 8\n",
      "Validation Error for l1 penalty value 3363038217.521232 is 1038554735941040.750000\n",
      "number of nonzeros = 8\n",
      "Validation Error for l1 penalty value 3406003414.842334 is 1043237237871703.000000\n",
      "number of nonzeros = 8\n",
      "Validation Error for l1 penalty value 3448968612.163436 is 1046937488751711.125000\n",
      "number of nonzeros = 7\n",
      "Validation Error for l1 penalty value 3491933809.484539 is 1051147625612860.875000\n",
      "number of nonzeros = 7\n",
      "Validation Error for l1 penalty value 3534899006.805641 is 1055992735342999.125000\n",
      "number of nonzeros = 7\n",
      "Validation Error for l1 penalty value 3577864204.126743 is 1060799531763287.750000\n",
      "number of nonzeros = 7\n",
      "Validation Error for l1 penalty value 3620829401.447845 is 1065707689498230.125000\n",
      "number of nonzeros = 6\n",
      "Validation Error for l1 penalty value 3663794598.768947 is 1069464335425586.500000\n",
      "number of nonzeros = 6\n",
      "Validation Error for l1 penalty value 3706759796.090049 is 1073504549585599.625000\n",
      "number of nonzeros = 6\n",
      "Validation Error for l1 penalty value 3749724993.411151 is 1077632775581416.000000\n",
      "number of nonzeros = 6\n",
      "Validation Error for l1 penalty value 3792690190.732254 is 1081867592324110.625000\n",
      "number of nonzeros = 6\n",
      "\n",
      "Lowest Validation Error for l1 penalty value 3448968612.163436 is 1046937488751711.125000\n"
     ]
    }
   ],
   "source": [
    "lowest_rss = 0.0\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model4 = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              verbose = False, validation_set = None,\n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty)\n",
    "    rss_validation = get_residual_sum_of_squares(model4, validation, validation['price'])\n",
    "    print \"Validation Error for l1 penalty value %f is %f\"%(l1_penalty, rss_validation)   \n",
    "    print 'number of nonzeros = %d' % (model4.coefficients['value']).nnz() \n",
    "    \n",
    "    if (lowest_rss == 0.0 or lowest_rss > rss_validation) and ((model4.coefficients['value']).nnz()== max_nonzeros):\n",
    "        lowest_rss = rss_validation\n",
    "        lowest_l1_penalty = l1_penalty\n",
    "        \n",
    "print \"\"\n",
    "print \"Lowest Validation Error for l1 penalty value %f is %f\"%(lowest_l1_penalty, lowest_rss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model5 = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              verbose = False, validation_set = None,\n",
    "                                              l2_penalty=0., l1_penalty=lowest_l1_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_penalty = 3.448969e+09\n",
      "number of nonzeros = 7\n",
      "Learned polynomial for degree 17:\n",
      "       14        13         5         4             3\n",
      "30.01 x  + 2899 x  + 690.1 x + 32.41 x + 1.587e+04 x + 661.7 x + 2.223e+05\n"
     ]
    }
   ],
   "source": [
    "print 'l1_penalty = %e' %lowest_l1_penalty\n",
    "print 'number of nonzeros = %d' % (model5.coefficients['value']).nnz()\n",
    "print_coefficients(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
